{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c333710",
   "metadata": {},
   "source": [
    "# Problem 4: Convexity of Generalized Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58dec8f",
   "metadata": {},
   "source": [
    "## (a)\n",
    "We have to find a formula for the canonical response function for generalized linear models. We have that $\\int b(y)e^{\\eta y-a(\\eta)}\\, dy = 1$. Differentiating with respect to $\\eta$, we find that\n",
    "\\begin{align}\n",
    "    0 &= \\frac{\\partial}{\\partial\\eta}\\int b(y)e^{\\eta y-a(\\eta)}\\, dy \\\\\n",
    "    &= \\int \\frac{\\partial}{\\partial\\eta}(b(y)e^{\\eta y-a(\\eta)})\\, dy\\\\\n",
    "    &= \\int(b(y)\\cdot e^{\\eta y-a(\\eta)}(y-\\frac{\\partial}{\\partial\\eta}a(\\eta))\\, dy\\\\\n",
    "    \\Rightarrow &\\int y b(y)\\cdot e^{\\eta y-a(\\eta)}\\, dy = \\int b(y)\\cdot e^{\\eta y-a(\\eta)}\\frac{\\partial}{\\partial\\eta}a(\\eta)\\, dy\\\\\n",
    "    \\Rightarrow & \\mathbb{E}[Y\\mid X;\\theta] = \\frac{\\partial}{\\partial\\eta}a(\\eta)\\int b(y)\\cdot e^{\\eta y-a(\\eta)}\\, dy=\\frac{\\partial}{\\partial\\eta}a(\\eta)\n",
    "\\end{align}\n",
    "and we conclude that $\\mathbb{E}[Y\\mid X;\\theta]=\\frac{\\partial}{\\partial\\eta}a(\\eta)$. The point is that to compute the optimal response function of a GLM, we just have to differentiate. \n",
    "\n",
    "Example: For logistic regression $a(\\eta)=\\log(1+e^{\\eta})$, so we recover the canonical response function\n",
    "\\begin{align}\n",
    "    h_{\\theta}(x)=\\mathbb{E}[Y\\mid X;\\theta]=\\frac{\\partial a}{\\partial\\eta}=\\frac{1}{1+e^{-\\eta}}\\cdot e^{\\eta}=\\frac{1}{1+e^{-\\theta^T x}}\n",
    "\\end{align}\n",
    "which is the sigmoid function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07fb3a",
   "metadata": {},
   "source": [
    "## (b)\n",
    "Now we derive a formula for the variance of the distribution. We compute\n",
    "\\begin{align}\n",
    "    \\frac{\\partial^2 a}{\\partial\\eta^2} &= \\frac{\\partial}{\\partial\\eta}\\mathbb{E}[Y\\mid X;\\theta]\\\\\n",
    "    &= \\frac{\\partial}{\\partial\\eta}\\int yb(y)e^{\\eta y-a(\\eta)}\\, dy\\\\\n",
    "    &=\\int yb(y)e^{\\eta y-a(\\eta)}(y-\\frac{\\partial a}{\\partial\\eta})\\, dy\\\\\n",
    "    &=\\int y^2 b(y)e^{\\eta y-a(\\eta)}\\, dy-\\frac{\\partial a}{\\partial\\eta}\\int yb(y)e^{\\eta y-a(\\eta)}\\, dy\\\\\n",
    "    &=\\mathbb{E}[Y^2\\mid X;\\theta]-\\mathbb{E}[Y\\mid X;\\theta]^2=\\mathbb{Var}[Y\\mid X;\\theta]\n",
    "\\end{align}\n",
    "as wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0335d0df",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Write out the NLL of the distribution as a function of $\\theta$, compute the Hessian, argue that it is PSD and therefore that the NLL of a GLM is convex, meaning that it has a global minimum. We compute\n",
    "\\begin{align}\n",
    "\\ell(\\theta) &= -\\log(\\prod_{i=1}^m p(y^{(i)}\\mid x^{(i)};\\theta))\\\\\n",
    "&= -\\log(\\prod_{i=1}^m b(y^{(i)})e^{\\theta^T x^{(i)}y^{(i)}-a(\\theta^T x^{(i)})})\\\\\n",
    "&=-\\sum_{i=1}^m\\log(b(y^{(i)})+\\theta^T x^{(i)}y^{(i)}-a(\\theta^T x^{(i)})\n",
    "\\end{align}\n",
    "Taking the second partial derivatives, we find that\n",
    "\\begin{align}\n",
    "\\frac{\\partial^2\\ell}{\\partial\\theta_i\\partial\\theta_j} &= \\sum_{k=1}^m\\frac{\\partial a(\\theta^T x^{(k)})}{\\partial\\theta_i\\partial\\theta_j}\\\\\n",
    "&=\\sum_{k=1}^m\\frac{\\partial^2 a(\\theta^T x^{(k)})}{\\partial (\\theta^T x^{(k)})^2}\\frac{\\partial (\\theta^T x^{(k)})}{\\partial\\theta_i}\\frac{\\partial (\\theta^T x^{(k)})}{\\partial\\theta_i}\\\\\n",
    "&=\\sum_{k=1}^m\\mathbb{Var}[Y\\mid x^{(k)};\\theta]x^{(k)}_i x^{(k)}_j\n",
    "\\end{align}\n",
    "That is, the second partial derivatives are inner products of the columns in the input data matrix $X$ weighted by positive numbers. Hence, we may write the Hessian as $X^T D X$, where $D$ is a diagonal matrix with non-negative entries on the diagonal. Hence, for any $z$ we have that $z^T X^T D X z = z^T X^T (D^{1/2})^T D^{1/2} X z = ||D^{1/2}Xz||_2^2\\geq 0$. Hence the NLL of a GLM is convex and we are through.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0880d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
